{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rock Paper Scissors\n",
    "\n",
    "Notebook demonstrating the FPN approach to learning the equilibrium to a parametrized rock paper scissors game.\n",
    "Samy Wu Fung, Howard Heaton, Qiuweil Li and Daniel McKenzie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from FPN import FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VINet(FPN):\n",
    "    '''\n",
    "        Test implementation of variational inequality net for learning to\n",
    "        solve a VI over the probability simplex.\n",
    "        \n",
    "        WARNING: This code is, as yet, untested.\n",
    "        \n",
    "        Daniel McKenzie, April 20th 2021\n",
    "        \n",
    "    '''\n",
    "    def __init__(self, action_dim, num_players, device,\n",
    "                 s_hi=1.0, inf_dim=10):\n",
    "        super().__init__()\n",
    "        self._device = device\n",
    "        self._lat_dim = action_dim*num_players\n",
    "        self._inf_dim = inf_dim\n",
    "        self._device = device\n",
    "        \n",
    "        # Layers\n",
    "        self.fc_u = nn.Linear(lat_dim, lat_dim, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def name(self):\n",
    "        return 'VINet'\n",
    "        \n",
    "    def device(self):\n",
    "        return self._device\n",
    "    \n",
    "    def lat_dim(self):\n",
    "        return self._lat_dim\n",
    "    \n",
    "    def s_hi(self):\n",
    "        return self._s_hi\n",
    "    \n",
    "    def project_to_simplex(self, u):\n",
    "        \"\"\"\n",
    "           function handling the projection to simplex.\n",
    "           From https://github.com/smatmo/ProjectionOntoSimplex\n",
    "\n",
    "        \"\"\"\n",
    "        batch_size = u.shape[0]\n",
    "        mu = torch.sort(u, descending=True)[0]\n",
    "        cum_sum = torch.cumsum(mu, dim=1)\n",
    "        # Don't actually need to track gradients in next step:\n",
    "        j = torch.unsqueeze(torch.arange(1,self._lat_dim + 1,\n",
    "                          dtype = mu.dtype, device = self._device),0)\n",
    "        rho = torch.sum(j*mu - cum_sum + 1. > 0.0,dim=1, keepdim=True) - 1.\n",
    "        rho = rho.long()\n",
    "        sum_to_rho = cum_sum[torch.arange(batch_size), rho[:,0]]\n",
    "        theta = (1 - torch.unsqueeze(sum_to_rho, -1))/(rho.type(sum_to_rho.dtype) + 1)\n",
    "        w = torch.clamp(theta + u, min=0.0)\n",
    "        return w\n",
    "    \n",
    "    def latent_space_forward(self, u, v):\n",
    "        u = 0.99*self.relu(self.fc_u(u) + v)\n",
    "        \n",
    "        # Now do projection on to simplex\n",
    "        \n",
    "        w = self.project_to_simplex(u)\n",
    "        \n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data\n",
    "\n",
    "The next few cells handle generating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the training data\n",
    "w_fixed = torch.randn(9) # hold fixed. Will determine dependence of payoff (P) on context (d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data d\n",
    "def generate_d(n):\n",
    "    # generate n random data\n",
    "    d = torch.rand(n,3)\n",
    "    return d\n",
    "\n",
    "# Creates payoff matrix P given d\n",
    "def create_Pmatrix(d, w=w_fixed):\n",
    "    batch_size = d.shape[0] # number of samples\n",
    "    P = torch.zeros(batch_size, d.shape[1], d.shape[1])\n",
    "\n",
    "    d1 = d[:,0]; d2 = d[:,1]; d3 = d[:,2]\n",
    "    P[:,0,1] = w[0]*d1 + w[1]*d2 + w[2]*d3\n",
    "    P[:,0,2] = w[3]*d1 + w[4]*d2 + w[5]*d3\n",
    "    P[:,1,0] = -w[0]*d1 - w[1]*d2 - w[2]*d3\n",
    "    P[:,1,2] = w[6]*d1 + w[7]*d2 + w[8]*d3\n",
    "    P[:,2,0] = -w[3]*d1 - w[4]*d2 - w[5]*d3\n",
    "    P[:,2,1] = -w[6]*d1 - w[7]*d2 - w[8]*d3\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_simplex(u, lat_dim, device):\n",
    "        \"\"\"\n",
    "            function handling the projection to simplex.\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = u.shape[0]\n",
    "        mu = torch.sort(u, descending=True)[0]\n",
    "        cum_sum = torch.cumsum(mu, dim=1)\n",
    "        # Don't actually need to track gradients in next step:\n",
    "        j = torch.unsqueeze(torch.arange(1,lat_dim + 1,\n",
    "                           dtype = mu.dtype, device = device),0)\n",
    "        rho = torch.sum(j*mu - cum_sum + 1. > 0.0,dim=1, keepdim=True) - 1.\n",
    "        rho = rho.long()\n",
    "        sum_to_rho = cum_sum[torch.arange(batch_size), rho[:,0]]\n",
    "        theta = (1 - torch.unsqueeze(sum_to_rho, -1))/(rho.type(sum_to_rho.dtype) + 1)\n",
    "        w = torch.clamp(theta + u, min=0.0)\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates true data z given P and d\n",
    "def generate_z(d, eps = 1e-4, max_iter=1000, verbosity=False):\n",
    "\n",
    "    batch_size = d.shape[0]\n",
    "    problem_dim = d.shape[1]\n",
    "    z = torch.zeros(batch_size, 2*problem_dim)\n",
    "    P = create_Pmatrix(d)\n",
    "    print(P.shape)\n",
    "    alpha = 1. # step size, can make this smaller if necessary.\n",
    "  \n",
    "    for j in range(max_iter):\n",
    "        z_old = z.clone()\n",
    "        player_1_grad = -torch.matmul(P,z[:,0:problem_dim])\n",
    "        player_2_grad = torch.matmul(torch.transpose(P, 1, 2), z[:,problem_dim+1:])\n",
    "        game_gradient = torch.cat(player_1_grad,player_2_grad)\n",
    "\n",
    "        # Take step of projected fixed point iteration\n",
    "        z = project_to_simplex(z - alpha*game_gradient)\n",
    "        diff_norm = torch.norm(z_old - z)\n",
    "        if verbosity ==True:\n",
    "            print('iter = ', j, '\\t |z_{k+1} - z_k| = ', diff_norm)\n",
    "\n",
    "        if diff_norm < eps:\n",
    "            return z\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3000x3 and 1000x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a9a6147e1b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgenerate_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-d7e2c76bd384>\u001b[0m in \u001b[0;36mgenerate_z\u001b[0;34m(d, eps, max_iter, verbosity)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mz_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mplayer_1_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mproblem_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mplayer_2_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproblem_dim\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mgame_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_1_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplayer_2_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3000x3 and 1000x3)"
     ]
    }
   ],
   "source": [
    "# Generate Data\n",
    "n = 1000; n_test = 100\n",
    "d_train = generate_d(n)\n",
    "d_test  = generate_d(n_test)\n",
    "\n",
    "train_z = generate_z(d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
